## Abstract

Gibson's theory of affordance, in its adherence to bottom-up direct perception, is
antithetical to the top-down inferential models often proposed by modern robotics
research purporting to tackle it. Such research assumes internal representation to
be sacrosanct, but given current developments, to what extent can this assumption
now be reexamined? The recently proposed sensorimotor contingency theory furthers
the theoretical argument that internal representation is unnecessary, and its
proof-of-concept application in robotics as well as the subsequent explosion in
deep learning methodology sheds new light on the possibility of equipping robots
with the capacity for directly perceiving their environments by exploiting correlated
changes in their sensory inputs triggered by executing specific motor programs. This
reexamination of direct perception is only one of several issues warranting scrutiny
in current robotic affordance research. The aim of this workshop is therefore twofold.

Firstly, we will provide an overview of the state-of-the-art in affordance research
and dissect open research challenges yielded thereof. 

Secondly, we will encourage our speakers to debate whether computational models of
affordance can potentially be advanced by adopting approaches that are more congruent
with Gibson's original conception of direct perception. 


### Previous edition

This workshop proposal is a sequel to the 1st edition of the International Workshop on Computational Models of Affordance in Robotics at RSS 2018. The rich and interdisciplinary discussions that took place there call for a second edition. Additionally, as the survey below shows [1], affordances are a topic of high interest in robotics, readily showing that such an interdisciplinary workshop is of high relevance to advance affordance research in robotics.

[1] Philipp Zech, Simon Haller, Safoura Rezapour Lakani, Barry Ridge, Emre Ugur, Justus Piater, [Computational models of affordance in robotics: a taxonomy and systematic classification.](https://iis.uibk.ac.at/public/papers/Zech-2017-AB.pdf) Adaptive Behavior, 25 (5), pp. 235â€“271, 2017. [SAGE](http://journals.sagepub.com/doi/10.1177/1059712317726357). 

### Topics

  * Affordance learning
  * Multimodal affordance learning
  * Affordance perception and vision for affordances
  * Perceptual learning and development
  * Babbling and exploration
  * Language and affordances
  * Learning from observation and mirroring
  * Self-organization of knowledge
  * Deep learning of affordances
  * Bayesian learning of affordances
  * Concept learning
  * Symbol emergence
  * Symbol grounding
  * Sensorimotor contingency theory
  * Behavior affording behavior
  * Actions and functions in object perception
  * Brain-body-environment systems
  * Agent-environment systems
  * Selective attention
  * Self-supervised learning
  * Sensing physical properties
  * Ecologically intuitive physics


### Call for Contributions

Participants are invited to submit contributions related to the aforementioned topics in one of the following categories:
  A) Extended abstract (maximum 2 pages in length)
  B) Full paper (maximum 8 pages in length)

Important dates:

  * Extended Submission Deadline: XXX, Y 2019
  * Notification of Acceptance: XXX, Y, 2019
  * Camera ready submission: XXX, Y, 20189

Submission are expected to follow the official ICRA style available at [To be updated](). Submissions are done via Microsoft CMT at [To be updated](https://cmt3.research.microsoft.com/IWCMAR2019)

All submissions will be peer-reviewed. Accepted papers will be presented during the workshop in a poster session. Outstanding papers will be presented as oral spotlight talks and invited to submit an extended version to a special issue of Frontiers in Neurorobotics on "Computational Models of Affordance for Robotics" __(to be updated, see below)__, a journal published by Frontiers. The review process for the journal is independent from the review for this workshop. 

### Special Issue

A *Frontiers in NeuroRobotics* special issue is __will be organized__ in tandem with the workshop.

While workshop contributors will be invited to submit extended versions of their workshop papers, general submissions will also be welcome.

Stay tuned for further announcements. 


### Submission

Submissions must be in PDF following the ICRA style available at:

   [To be updated](http://www.roboticsconference.org/docs/paper-template-latex.tar.gz)
   
and uploaded via the Microsoft CMT conference management system here:

   [To be updated](https://cmt3.research.microsoft.com/IWCMAR2018)
   
Submission is not open yet !

### Papers

The accepted papers are listed as follows:

  * Not item yet !
  
### Expected speakers

  * Yiannis Aloimonos (Robotics) [Confirmed]
  * Tamim Asfour  (Robotics) [Confirmed]
  * Paul Cisek (Neuroscience) [Confirmed]
  * Verena V. Hafner (Robotics) [Pending]
  * Tony Chemero (Philosophy, Cognitive Science) [Pending]
  * Claire Michaels (Psychology) [Pending]
  
### Tentative schedule
| Time        | Activity                                       |
|-------------|------------------------------------------------|
| 8:30-9:00   | Welcome                                        |
| 9:00 - 9:30 | Invited Talk                                   |
| 9:30-10:00  | Invited Talk                                   |
| 10:00-10:30 | Coffee break                                   |
| 10:30-11:00 | Invited Talk                                   |
| 11:00-11:30 | Invited Talk                                   |
| 11:30-12:00 | Time buffer for discussion after invited talks |
| 12:00-13:30 | Lunch break                                    |
| 13:30-14:00 | Invited talk                                   |
| 14:00-14:30 | Invited talk                                   |
| 14:30-15:30 | Poster session                                 |
| 15:30-16:00 | Coffee break                                   |
| 16:00-17:00 | Plenary discussion                             |
| 17:00-17:30 | Farewell                                       |
    
### Information
 
 To be updated: 
 
   * Agenda
   * Organizers
   * Venue
